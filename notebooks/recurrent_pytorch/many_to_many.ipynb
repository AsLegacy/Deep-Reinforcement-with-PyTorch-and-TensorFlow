{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Decoder (Many-to-Many) with LSTM in Pytorch\n",
    "This is a simple encoder/decoder module with the Many-to-Many simple pattern. This means that the outtput sequence size must match the input sequence size.\n",
    "![alt text](imgs/sequnce_types.png \"Types\")\n",
    "\n",
    "### Problem\n",
    "The input message will be encrypted simply by adding 2 elements on alphabet position (ie: A-->C, B-->D, etc...)\n",
    "\n",
    "### Creating LSTM layer in Pytorch easy way\n",
    "```python\n",
    "# Step 1\n",
    "lstm = torch.nn.LSTM(input_size=5, hidden_size=10, batch_first=True)\n",
    "```\n",
    "\n",
    "### References\n",
    "* https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "* http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "* https://medium.com/@nikhilweee/building-your-first-rnn-with-pytorch-8568b6f2ec71\n",
    "* https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a\n",
    "* https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "* https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones\n",
    "* https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "* https://www.quora.com/What-does-PyTorch-Embedding-do\n",
    "* https://stackoverflow.com/questions/50747947/embedding-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "vocab = [char for char in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ-']\n",
    "num_epochs = 10\n",
    "\n",
    "batch_size = 128\n",
    "embedding_dim = 10\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDEFGHIJKLMNOPQRSTUVWXYZ-AB\n",
      "Encrypted: NGQ\n",
      "Decrypted: LEO\n"
     ]
    }
   ],
   "source": [
    "# Jumpt 13 characters\n",
    "def encrypt(text, key = 2):\n",
    "    \"\"\"Returns the encrypted form of 'text'.\"\"\"\n",
    "    indexes = [vocab.index(char) for char in text]\n",
    "    encrypted_indexes = [(idx + key) % len(vocab) for idx in indexes]\n",
    "    encrypted_chars = [vocab[idx] for idx in encrypted_indexes]\n",
    "    encrypted = ''.join(encrypted_chars)\n",
    "    return encrypted\n",
    "\n",
    "\n",
    "def decrypt(text, key = 2):\n",
    "    \"\"\"Returns the encrypted form of 'text'.\"\"\"\n",
    "    indexes = [vocab.index(char) for char in text]\n",
    "    encrypted_indexes = [(idx - key) % len(vocab) for idx in indexes]\n",
    "    encrypted_chars = [vocab[idx] for idx in encrypted_indexes]\n",
    "    encrypted = ''.join(encrypted_chars)\n",
    "    return encrypted\n",
    "\n",
    "print(encrypt('ABCDEFGHIJKLMNOPQRSTUVWXYZ-'))\n",
    "enc_msg = encrypt('LEO')\n",
    "print('Encrypted:',enc_msg)\n",
    "dec_msg = decrypt(enc_msg)\n",
    "print('Decrypted:',dec_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset\n",
    "Create a list size (batch_size) of encrypted/decrypted message tensors.\n",
    "\n",
    "#### Some important points about sequence Modelling\n",
    "On Sequence training, each sample on the batch need to follow some order, but the samples on the batch doesnt need to have correlation in time between themselves.\n",
    "\n",
    "Also in theory the samples inside the batch doesnt need to have the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(batch_size, message_length = 32):\n",
    "    \"\"\"Returns a list of 'num_examples' pairs of the form (encrypted, original).\n",
    "\n",
    "    Both elements of the pair are tensors containing indexes of each character\n",
    "    of the corresponding encrypted or original message.\n",
    "    \"\"\"\n",
    "    # We could change the sample size in between samples on the same batch\n",
    "    message_length = random.randint(10, 32)\n",
    "    dataset = []\n",
    "    for x in range(batch_size):\n",
    "        ex_out = ''.join([random.choice(vocab) for x in range(message_length)])\n",
    "        # may be: MANR-TQNNAFEGIDE-OXQZANSVEMJXWSU\n",
    "        ex_in = encrypt(''.join(ex_out))\n",
    "        \n",
    "        # may be: ZN-DMFC--NSRTVQRMAJCLN-EHRZWJIEG (Model Input)\n",
    "        ex_in = [vocab.index(x) for x in ex_in]\n",
    "        # may be: [25, 13, 26, 3, 12, 5, 2, 26, 26, (Model Label)\n",
    "        ex_out = [vocab.index(x) for x in ex_out]\n",
    "        \n",
    "        # Return a batch\n",
    "        # may be: [12, 0, 13, 17, 26, 19, 16, 13, ...\n",
    "        dataset.append([torch.tensor(ex_in), torch.tensor(ex_out)])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and instantiate LSTM Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim = 8):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # Create Embedding of \"vocabulary size tensors\" of size \"embedding_dim\"\n",
    "        self.embed = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Create LSTM layer (input_size, size_hidden_features)\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "        # Create FC layer (input_size, output_size)\n",
    "        self.linear = torch.nn.Linear(hidden_dim, vocab_size)\n",
    "        # Create Softmax Layer\n",
    "        self.softmax = torch.nn.functional.softmax\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Convert the letters to dense vectors (Easier for the LSTM to learn)\n",
    "        lstm_in = self.embed(input)\n",
    "        # Add extra dimentsion to the input\n",
    "        lstm_in = lstm_in.unsqueeze(1)\n",
    "        \n",
    "        # Run the LSTM layer with a batch of samples\n",
    "        lstm_out, lstm_hidden = self.lstm(lstm_in, self.initHidden())\n",
    "        \n",
    "        # Run the FC layer\n",
    "        scores = self.linear(lstm_out)\n",
    "        \n",
    "        # Run softmax layer (Convert to probabilities)\n",
    "        predictions = self.softmax(scores, dim=2)\n",
    "        return scores, predictions\n",
    "\n",
    "    # Initialize hiddem and cell state before each batch\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_dim),torch.zeros(1, 1, self.hidden_dim))\n",
    "\n",
    "\n",
    "decoder_lstm = DecoderLSTM(vocab_size=vocab_size, embedding_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(decoder_lstm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: 3.1466\n",
      "Epoch: 1\n",
      "Loss: 2.8361\n",
      "Epoch: 2\n",
      "Loss: 2.3299\n",
      "Epoch: 3\n",
      "Loss: 2.0675\n",
      "Epoch: 4\n",
      "Loss: 1.5893\n",
      "Epoch: 5\n",
      "Loss: 1.3763\n",
      "Epoch: 6\n",
      "Loss: 1.2076\n",
      "Epoch: 7\n",
      "Loss: 0.9377\n",
      "Epoch: 8\n",
      "Loss: 0.8511\n",
      "Epoch: 9\n",
      "Loss: 0.6529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11ced67f0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies, max_accuracy = [], 0\n",
    "all_losses = []\n",
    "for x in range(num_epochs):\n",
    "    print('Epoch: {}'.format(x))\n",
    "    for encrypted_msgs, label_msgs in dataset(batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        scores,_ = decoder_lstm(encrypted_msgs)\n",
    "        # scores.size() = [64, 1, 27], but loss_fn expects a tensor\n",
    "        # of size [64, 27, 1]. So we switch the second and third dimensions.\n",
    "        scores = scores.transpose(1, 2)\n",
    "        # original.size() = [64], but original should also be a 2D tensor\n",
    "        # of size [64, 1]. So we insert a fake dimension.\n",
    "        label_msgs = label_msgs.unsqueeze(1)\n",
    "        # Calculate loss.\n",
    "        loss = loss_fn(scores, label_msgs) \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    all_losses.append(loss.item())\n",
    "    print('Loss: {:6.4f}'.format(loss.item()))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        matches, total = 0, 0\n",
    "        for encrypted_msgs, label_msgs in dataset(batch_size):\n",
    "            scores,predictions = decoder_lstm(encrypted_msgs)\n",
    "            # Choose the letter with the maximum probability\n",
    "            _, batch_out = predictions.max(dim=2)\n",
    "            # Remove fake dimension\n",
    "            batch_out = batch_out.squeeze(1)\n",
    "            # Calculate accuracy\n",
    "            matches += torch.eq(batch_out, label_msgs).sum().item()\n",
    "            total += torch.numel(batch_out)\n",
    "        accuracy = matches / total\n",
    "        print('Accuracy: {:4.2f}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on a single message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label text (Expected output)\n",
      "['M', 'K', 'P', 'X', 'N', 'Z', 'E', 'G', 'S', 'Z', 'R', 'N', 'U', 'I', '-', 'D']\n"
     ]
    }
   ],
   "source": [
    "sample = dataset(1)\n",
    "encrypted_msgs = sample[0][0]\n",
    "label_msgs = sample[0][1]\n",
    "print('\\nLabel text (Expected output)')\n",
    "label_msgs_chars = [vocab[char] for char in label_msgs]\n",
    "print(label_msgs_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [14 12 17 25 15  0  6  8 20  0 19 15 22 10  1  5]\n",
      "\n",
      "Expected output: [12 10 15 23 13 25  4  6 18 25 17 13 20  8 26  3]\n",
      "\n",
      "Model output: [12 10 15 23 13 25  4  6 18 25 17 13 20  8 26  3]\n",
      "\n",
      "Decrypted text\n",
      "['M', 'K', 'P', 'X', 'N', 'Z', 'E', 'G', 'S', 'Z', 'R', 'N', 'U', 'I', '-', 'D']\n"
     ]
    }
   ],
   "source": [
    "scores,predictions = decoder_lstm(encrypted_msgs)\n",
    "_, batch_out = predictions.max(dim=2)\n",
    "batch_out = batch_out.squeeze(1)\n",
    "decrypted_msg_model = batch_out.numpy()\n",
    "\n",
    "print('Input:',encrypted_msgs.numpy())\n",
    "print('\\nExpected output:',label_msgs.numpy())\n",
    "print('\\nModel output:',decrypted_msg_model)\n",
    "\n",
    "print('\\nDecrypted text')\n",
    "decrypted_msg_chars = [vocab[char] for char in decrypted_msg_model]\n",
    "print(decrypted_msg_chars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
