{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction Sequence to Sequence Models\n",
    "Those are the models that are used on Machine translation. Different than the many-to-many approach, the sequence to sequence can output a sequence with size different than the input sequence.\n",
    "This example we're going to learn about the encoder/decoder architecture (Without attention)\n",
    "\n",
    "### Encoder / Decoder architecture.\n",
    "The sequence to sequence model is divided on an encoder network that condense the input sequence into the hidden vector, and an decoder consume the hidden vector into another sequence.\n",
    "![alt text](imgs/seq_to_seq_anim.gif \"Sequence to Sequence\")\n",
    "The problem of this method is that we will condense a sequence of unknown size into a hidden vector of fixed size, which means some information will be lost. To mitigate this we can use the Attention mechanism.\n",
    "\n",
    "### Words Representation\n",
    "The words will be converted to an index value. Those index sequence will be fed to both encoder and decoder.\n",
    "Internally the encoder and decoder has an embedding layer that will learn from your data the best vector to represent each word. (sort of automatic word2vec)\n",
    "![alt text](imgs/embedding_RNN.png \"Sequence to Sequence\")\n",
    "\n",
    "\n",
    "### References\n",
    "* https://towardsdatascience.com/transformers-141e32e69591\n",
    "* https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "* https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "* http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "* https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\n",
    "* https://github.com/harvardnlp/annotated-transformer\n",
    "* https://arxiv.org/pdf/1902.10525.pdf\n",
    "* https://distill.pub/2017/ctc/\n",
    "* https://distill.pub/2019/memorization-in-rnns/\n",
    "* https://jalammar.github.io/illustrated-word2vec/\n",
    "* https://www.youtube.com/watch?v=quoGRI-1l0A\n",
    "* https://www.youtube.com/watch?v=SysgYptB198\n",
    "* https://medium.com/synapse-dev/understanding-bert-transformer-attention-isnt-all-you-need-5839ebd396db\n",
    "* https://www.youtube.com/watch?v=0EtD5ybnh_s\n",
    "* https://discuss.pytorch.org/t/detach-no-grad-and-requires-grad/16915/3\n",
    "* https://medium.com/datadriveninvestor/attention-in-rnns-321fbcd64f05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute device: cpu\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "#from torchsummary import summary\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from utils_seq_to_seq import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Compute device:',device)\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10\n",
    "hidden_size = 256\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "# Writer for Tensorboard X\n",
    "writer = SummaryWriter('./logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi hello world ! what s your name ?\n",
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "['je suis aussi choquee que toi .', 'i m as shocked as you are .']\n"
     ]
    }
   ],
   "source": [
    "# Convert to lowercase and simplify expressions\n",
    "print(normalizeString('Hi hello world! What\\'s your name?'))\n",
    "# Load dataset\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "# Get some X-Y data\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "The encoder input will be input sequence word index, and the previous output (hidden state). The Encoder has an embedding layer so it will automatically learn an embedding based on your data.\n",
    "![alt text](imgs/Encoder.png \"Sequence to Sequence\")\n",
    "#### Shapes\n",
    "```\n",
    "    Input shape: torch.Size([1])\n",
    "    Hidden shape: torch.Size([1, 1, 256])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = input.type(torch.LongTensor)\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "We will pull out of the decoder the output sequece, starting by giving the encoder accumulated hidden_vector and the SOS(start of sequence) input. \n",
    "\n",
    "After that the decoder will receive the last decoded word and it's own hidden state.\n",
    "![alt text](imgs/Decoder.png \"Sequence to Sequence\")\n",
    "\n",
    "#### Shapes\n",
    "```\n",
    "Input shape: torch.Size([1, 1])\n",
    "Hidden shape: torch.Size([1, 1, 256])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # The embedding layer will learn a word2vec with your training data\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):        \n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Functions\n",
    "On this step we will do the backpropagation trough time to train our sequence to sequence model. Observe that we calculate the loss for each time step of the target sequence.\n",
    "\n",
    "#### Teacher Forcing\n",
    "It's a technique used to make the sequence to sequence model converge faster, by giving the target word to the decoder input instead of the decoder previous word guess.\n",
    "![alt text](imgs/RNN_SEQ_2_SEQ_TRAIN.png \"Sequence to Sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    # Start encoder hidden state as zero\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    # Zero the gradient for doing backprop\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Get input/output sequence lenghts (the sequences has indexes of words not words....)\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)    \n",
    "\n",
    "    # Initialize Loss\n",
    "    loss = 0\n",
    "\n",
    "    # Push input sequence into encoder and accumulate into encoder_hidden\n",
    "    # Imagine it's reading the text and memorizing....\n",
    "    for ei in range(input_length):\n",
    "        _, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)        \n",
    "\n",
    "    # Prepare Decoder input (SOS(Start of sequence) and encoder hidden state)\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # Roll the dice to decide if we should use teacher_forcing\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            # Run one decoder timestep\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            \n",
    "            # Push into the decoder the last target word (Teacher forcing) \n",
    "            decoder_input = target_tensor[di]\n",
    "            \n",
    "            # Calculate the loss\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions (Decoder guess) as the next input\n",
    "        for di in range(target_length):\n",
    "            # Run one decoder timestep\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            \n",
    "            # Push into the decoder the top1 decoded word\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            # Put the last word guessed by the decoder as next decoder input)\n",
    "            # detach is useful when you want to compute something that you don’t want to differentiate.             \n",
    "            decoder_input = topi.squeeze().detach()  \n",
    "\n",
    "            # Calculate the loss\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            \n",
    "            # Or finsh when the input is EOS\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    # Calculate the loss gradient wrt to the model weights\n",
    "    loss.backward()\n",
    "\n",
    "    # Do the gradient descent step\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    # Return normalized loss\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    # Initialize SGD Optimizer to train the network\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Load #n_iters pairs from the dataset (ie: je suis --> I am) (Data on index format)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs), input_lang, output_lang, device)\n",
    "                      for i in range(n_iters)]\n",
    "    \n",
    "    # negative log likelihood loss.\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        # Select a sample\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        # Convert sample index list to string to log on tensorboard\n",
    "        target_string_list = [output_lang.index2word[index.item()] for index in target_tensor]\n",
    "        input_string_list = [input_lang.index2word[index.item()] for index in input_tensor]        \n",
    "        writer.add_text('data/Sample', ' '.join(input_string_list) + ' --> ' + ' '.join(target_string_list), iter)        \n",
    "\n",
    "        # Train on that particular input/output sequence\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        # Accumulate Loss for display\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        # Send loss to Tensorboard\n",
    "        writer.add_scalar('loss/train', loss, iter)\n",
    "\n",
    "        # Log some information\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "        # Log some information\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    # Display loss plot\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Functions\n",
    "With the model trained we do the following....\n",
    "1. Push input sequence (list of indexes) into the Encoder\n",
    "2. Accumulate all into encoder hidden state\n",
    "3. Start Decoder with <SOS> and encoder hidden state\n",
    "4. Push into decoder the last hidden state and the previous most probable word (index) (top1)\n",
    "    \n",
    "![alt text](imgs/seq_2_seq_simple_eval.png \"Sequence to Sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence, device)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()        \n",
    "\n",
    "        # Push input sequence into encoder and accumulate into encoder_hidden\n",
    "        for ei in range(input_length):\n",
    "            _, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)            \n",
    "\n",
    "        # Prepare Decoder input (SOS(Start of sequence) and encoder hidden state)\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # List with output words\n",
    "        decoded_words = []\n",
    "\n",
    "        # Pull the sequence out of the decoder and append results into decoded_words\n",
    "        for di in range(max_length):\n",
    "            # Push into the decoder the last hidden state and the top1 last decoded word\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            # Get first topk results (Greedy most probable word from output)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            \n",
    "            # Append more words to the output or finish (received EOS)\n",
    "            if topi.item() == EOS_token:\n",
    "                # Stop if End of sequence <EOS>\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                # Append word to decoded_words\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            # Put back to the input the word with highest score\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words\n",
    "\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Encoder and Decoder Networks\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "# Push Graphs to Tensorboard\n",
    "encoder_dummy_x = (torch.rand(1).type(torch.LongTensor), torch.rand(1, 1, 256))\n",
    "decoder_dummy_x = (torch.rand(1,1).type(torch.LongTensor), torch.rand(1, 1, 256))\n",
    "writer.add_graph(encoder1, encoder_dummy_x)\n",
    "# Multiple graphs are not supported at the moment on tensorboard\n",
    "#writer.add_graph(decoder1, decoder_dummy_x)\n",
    "\n",
    "# Train\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)\n",
    "\n",
    "# Evaluate\n",
    "evaluateRandomly(encoder1, decoder1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
